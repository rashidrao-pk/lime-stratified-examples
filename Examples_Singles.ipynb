{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36de9f41",
   "metadata": {},
   "source": [
    "Code Available:       https://github.com/amparore/lime-stratified<br>\n",
    "Examples Available:   https://github.com/rashidrao-pk/lime-stratified-examples <br>\n",
    "If you use this code, please cite us: <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660877ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stretch Notebook Width to 98% size of the Screen\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0224169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/amparore/lime-stratified lime_stratified\n",
    "# cd lime_stratified\n",
    "# Changes in Downloaded LIME\n",
    "# make sure to do changes after downloading the LIME Image\n",
    "\n",
    "# python setup.py build\n",
    "# python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb05563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will use the modified code of lime downloaded from https://github.com/amparore/lime-stratified lime_stratified\n",
    "\n",
    "import lime\n",
    "from lime import lime_image\n",
    "lime.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e541ee8d",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0c5dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import utils as ut\n",
    "import importlib\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "import skimage\n",
    "import matplotlib\n",
    "import shap\n",
    "import json\n",
    "import cv2\n",
    "print('Python Version:\\t',sys.version)\n",
    "print('TensorFlow Verion:\\t',tf.__version__)\n",
    "print('Skimage Verion:\\t\\t',skimage.__version__)\n",
    "print('Numpy Verion:\\t\\t',np.__version__)\n",
    "print('Matplotlib Verion:\\t',matplotlib.__version__)\n",
    "print('SHAP Verion:\\t\\t',shap.__version__)\n",
    "print('JSON Version:\\t\\t',json.__version__)\n",
    "print('Pandas Version:\\t\\t',pd.__version__)\n",
    "print('Scipy Version:\\t\\t',scipy.__version__)\n",
    "print('OpenCV-Python Version:\\t',cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c32f37",
   "metadata": {},
   "source": [
    "### Setting Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc951da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Current Working Directory and joining subfolders and subfiles path\n",
    "Main_dir =   os.getcwd()\n",
    "DS_path =  os.path.join(Main_dir, \"data\")\n",
    "result_folder = os.path.join(Main_dir, \"result\")\n",
    "json_file    =  os.path.join(DS_path,\"imagenet_class_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43558bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting ImageNet class names\n",
    "class_names = ut.get_ImageNet_ClassLabels(json_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c74fa",
   "metadata": {},
   "source": [
    "## BlackBox Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8464c53",
   "metadata": {},
   "source": [
    "Load BlackBox Model, here ResNet50 Model is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86051347",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ResNet50'\n",
    "model = ut.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd948f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict image after preprocessing according to ResNet-50 Model on passed image \n",
    "def bb_predict(image):\n",
    "    return model.predict(preprocess_input(image,data_format='channels_last') , verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea1a78",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4209e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################    WEIGHT FUNCTIONS TO RESOLVE BIASNESS in WEIGHTS ######################\n",
    "import math\n",
    "# from l1 distance between @a and the vectors of ones, to the cosine distance\n",
    "def l1ones2cos(a,N):\n",
    "    b = N - a\n",
    "    return 1 - (0 if b==0 else b / math.sqrt(b*N))\n",
    "\n",
    "# probability of draw i values of 1 out of k samples of Binomial(0.5)\n",
    "def weight_mask(k,i):\n",
    "    return scipy.special.binom(k,i) / (2 ** k)\n",
    "# kernel for quantization using the L1 distance metric\n",
    "def old_quant_kernel_l1_fn(d, kernel_width,num_segments):\n",
    "    d = np.array([l1ones2cos(v, num_segments) for v in d])      # L1 -> cosine\n",
    "    d = np.array([w * weight_mask(num_segments, w) for w in d]) # weight by strata density\n",
    "    return np.sqrt(np.exp(-(d ** 2) / kernel_width ** 2))       # apply LIME kernel\n",
    "def quant_kernel_l1_fn(d, kernel_width, num_segments):\n",
    "    d2 = np.array([l1ones2cos(v, num_segments) for v in d])    # L1 -> cosine\n",
    "    d3 = np.array([d2[i] * weight_mask(num_segments, d[i]) for i in range(len(d))]) # weight by strata density\n",
    "    return np.sqrt(np.exp(-(d3 ** 2) / kernel_width ** 2))     # apply LIME kernel\n",
    "\n",
    "# original kernel function used by LIME, for cosine dissimilarity.\n",
    "def kernel_cosine_fn(d, kernel_width):\n",
    "    return np.sqrt(np.exp(-(d ** 2) / kernel_width ** 2))\n",
    "\n",
    "# will get the same result of the original kernel/cosine, but starting from the L1 distance metric\n",
    "def kernel_l1_fn(d, kernel_width,num_segments):\n",
    "    d = np.array([l1ones2cos(v, num_segments) for v in d])\n",
    "    return np.sqrt(np.exp(-(d ** 2) / kernel_width ** 2))\n",
    "##################################################################################\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    \"\"\"Given two dictionaries, merge them into a new dict as a shallow copy.\"\"\"\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7918af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These hyperparameters can be used to create LIME Image Explanations\n",
    "batch_size = 600\n",
    "num_samples = 1000\n",
    "top_labels = 2\n",
    "\n",
    "#######################################################################################################\n",
    "#    Run Experiments using these combinations\n",
    "## SEGMENTATION PARAMETERS\n",
    "seg_algo = 'quickshift'\n",
    "segs_range_list = [[0,50],[50,100],[100,150],[150,200]]\n",
    "\n",
    "hide_color = [None] #[None,0]\n",
    "use_stratification = [False,True]\n",
    "distance_function = ['cosine']# ,'l1']\n",
    "#######################################################################################################\n",
    "#  Results of Experiments\n",
    "plot_prediction = True #  Set it to True if plots for explanations are needed to be plot, Default: False\n",
    "plot_segments = True\n",
    "plot_explanation = True\n",
    "plot_classification_score = True\n",
    "plot_heatmap = True\n",
    "plot_image_mask = True \n",
    "save_explanations_as_plot = True #  Set it to True if plots for explanations are needed to be saved also, Default: False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bccea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "segs_param_table_all = []\n",
    "segs_param_table_sucess = []\n",
    "\n",
    "sub_results__ = os.path.join(result_folder,str(segs_range_list))\n",
    "sub_results_ = os.path.join(sub_results__,str(num_samples))# Create Segments File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb8cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# segs_param_table_all = []\n",
    "# segs_param_table_sucess = []\n",
    "# segs_range_list = [[0,100],[100,200],[200,300]]\n",
    "\n",
    "# sub_results__ = os.path.join(result_folder,str(segs_range_list))\n",
    "# sub_results_ = os.path.join(sub_results__,str(num_samples))\n",
    "\n",
    "\n",
    "# files= range(0,150,1)\n",
    "# data_to_csv = dict()\n",
    "# segs_param_table_sucess = []\n",
    "# #######   TO Run for All Files    \n",
    "\n",
    "# for f in files:\n",
    "#     file_name = f'{f+1:08}'\n",
    "#     file = os.path.join(DS_path,'ILSVRC2012_test_'+file_name+'.JPEG')\n",
    "#     print('Filename:',file_name,'\\t',file)      \n",
    "# #       Read and resize image according to model Input Layer\n",
    "#     image   = ut.read_process_image(file,model)\n",
    "#     for srl in segs_range_list:\n",
    "#         target_seg_no = srl[1]\n",
    "#         md,ks = ut.search_segment_number(image, target_seg_no=target_seg_no, init_max_dist=100,init_kernel_size=4,seg_algo=seg_algo)\n",
    "#         segments,segs,segmenter_fn = ut.own_seg(image,md=md,ks=ks)\n",
    "#         segs_param_table = {'filename':file_name, 'max_distance':md,'kernal_size':ks,'segments':segs,'seg_range':srl,'seg_algo':seg_algo}\n",
    "#         segs_param_table_sucess.append(segs_param_table)\n",
    "#         print('File:',file_name,' Creating ',segs, ' seg_range : ',srl,' [ ',md,' - ',ks,' ] ')\n",
    "#         df_seg = pd.DataFrame(segs_param_table_sucess)\n",
    "#         df_seg.to_csv(DS_path+'//Segmentation_Table_'+str(model_name)+'.csv', sep = ';' , index=False)\n",
    "# df_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765607dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Hyper Parametr file to create Segments\n",
    "# df_seg = pd.read_csv(sub_results__+'//Segmentation_Table_'+str(model_name)+str(segs_range_list)+'_'+str(time_stamp)+'.csv', sep = ';')\n",
    "df_seg = pd.read_csv(DS_path+'//Segmentation_Table_'+str(model_name)+str(segs_range_list)+'.csv', sep = ';')\n",
    "df_seg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0612ebbf",
   "metadata": {},
   "source": [
    "### Running Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e31b6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(ut)\n",
    "files= [125]\n",
    "results_csv = []\n",
    "#######    To Run for Selective Files\n",
    "for f in files:\n",
    "    file_name = f'{f:08}'\n",
    "    file = os.path.join(DS_path,'ILSVRC2012_test_'+file_name+'.JPEG')\n",
    "    file_name = ut.get_file_name(file)\n",
    "    sub_results = os.path.join(sub_results_,file_name)        \n",
    "    ut.check_folders(sub_results)\n",
    "\n",
    "#       Read and resize image according to model Input Layer\n",
    "    image   = ut.read_process_image(file,model)\n",
    "    image_arr = np.expand_dims(image,axis = 0)\n",
    "    predicted = bb_predict(image_arr)\n",
    "#         Convert the Predicted into Predicted Class Index (PDI), Class Probability, and Predicted Class Label (PDL)\n",
    "    (PDI,class_prob,PDL) =  ut.get_class_idx_label_score (predicted,class_names)\n",
    "\n",
    "#       Plot the blackbox model prediction \n",
    "    if plot_prediction:\n",
    "        ut.plot_save_prediction(image,PDL,class_prob,sub_results,file_name,\n",
    "                                plot_everything=save_explanations_as_plot,save_image=True)\n",
    "\n",
    "    df_n = df_seg.loc[(df_seg['filename'] == int(file_name))]\n",
    "#     iterrows\n",
    "    for data, row in df_n.T.iteritems():\n",
    "        filename_seg,md,ks = row.filename,row.max_distance,row.kernal_size\n",
    "        segments,segs,segmenter_fn = ut.own_seg(image,md=md,ks=ks)\n",
    "        sr = ut.segs_sections(segs,segs_range_list)\n",
    "        for hc in hide_color:\n",
    "            for us in use_stratification:\n",
    "                for dist_fn in distance_function:\n",
    "                    if dist_fn=='l1':\n",
    "                        kernel=(lambda d,kernel_width : kernel_l1_fn(d,kernel_width,segs))\n",
    "                    else:\n",
    "                        kernel=None\n",
    "                    data_to_csv = dict()\n",
    "                    \n",
    "#####               Fix Random Seed to make benchmark deterministic and reproducible\n",
    "                    explainer_lime = lime_image.LimeImageExplainer(random_state=1234, kernel = kernel)\n",
    "#####               Plot the segments Created \n",
    "                    if plot_segments:\n",
    "                        ut.plot_seg_image(image,segments,md,ks,sub_results,file_name,save_image=True)\n",
    "#####               Create Explanation\n",
    "                    explanation_ret = explainer_lime.explain_instance(image, \n",
    "                                                     bb_predict,\n",
    "                                                     hide_color=hc,\n",
    "                                                     distance_metric=dist_fn,\n",
    "                                                     top_labels=top_labels,\n",
    "                                                     batch_size = batch_size,\n",
    "                                                     use_stratification = us,\n",
    "                                                     num_samples=num_samples,\n",
    "                                                     segmentation_fn = segmenter_fn)\n",
    "#                   Checking the datatype of returned variable from LIME-Image explain_instance function, \n",
    "#                                   if it is a tuple then split it into 3 variables\n",
    "                    if isinstance(explanation_ret, tuple):\n",
    "                        data, labels,explanation = explanation_ret\n",
    "                    else:\n",
    "                        explanation = explanation_ret\n",
    "                        data, labels = None, None\n",
    "###############################################    Evaluating EXPLANATIONS  ###########################################################\n",
    "                    if data is not None and labels is not None:\n",
    "                        TopLabel = explanation.top_labels[0] \n",
    "                        hcc = 'mean-filled' if hc is None else 'zero-filled'\n",
    "                        ttl = str(segs)+'_'+hcc+'_'+str(us)+'_'+str(num_samples)               \n",
    "#                       Building a Dictionary with Keys and Values to write into Data File\n",
    "\n",
    "                        data_to_csv = {'filename':str(file_name),'hide_color':str(hcc),'use_stratification':str(us),'num_samples':str(num_samples),\n",
    "                        'dist_fn':str(dist_fn),'segments':str(segs),'max_dist':str(md),'kernal_size':str(ks)}\n",
    "        \n",
    "#                       Evaluate Explanation and get dictionary back with all evaluation results\n",
    "                        ut.evaluate_explanation(explanation,data,labels,class_prob,data_to_csv,model_name,sr)\n",
    "####################################           PLOTTING CLASSIFICATION SCORE           #####################################################\n",
    "#                 This will generate the Classification Score of Linear Regressor\n",
    "                        if plot_classification_score:\n",
    "                            ut.plot_classification_score(explanation,data,labels,class_prob,sub_results,ttl,\n",
    "                                                         plot_everything=save_explanations_as_plot,draw_quantile=False,save_image=True)\n",
    "\n",
    "####################################           PLOTTING HEATMAP                   #####################################################\n",
    "######                      This will generate heatmap plot based on feature importances computed by us from explanation returned by LIME Image Explainer\n",
    "                        if plot_classification_score:\n",
    "                            heatmap = ut.fun_create_heatmap_lime(image,explanation,TopLabel,segments)\n",
    "                            ut.plot_heatmap_lime(heatmap,data_to_csv['maxval'],sub_results,ttl,save_result=True,\n",
    "                                                 show_color_bar=False,color_bar_location='right')\n",
    "                        ######################################################################################\n",
    "        #                 GET IMAGE AND MASK BY LIME\n",
    "                        if plot_image_mask:\n",
    "                            ut.get_img_mask_lime(explanation,TopLabel, sub_results,ttl,save_image=True,positive_only=True, num_features=5, hide_rest=True)\n",
    "                        results_csv.append(data_to_csv)\n",
    "                        print(data_to_csv)\n",
    "                        df_data = pd.DataFrame(results_csv)\n",
    "                        df_data.to_csv(os.path.join(sub_results_, file_name+'_data.csv'), sep = ';', index=False)\n",
    "                        print('ImageNo: ',file_name,'distance:',dist_fn,', Segs:',str(segs),', Max_Dist: ',md,', Kernal Size: ',ks, ', Hide_Color: ',str(hc),', Use_Stratification: ',str(us),', CV: ',str(data_to_csv['cv_beta']))\n",
    "                    else:\n",
    "                        print('Data and Labels needs to be returned from lime_image.py function')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f899e3f",
   "metadata": {},
   "source": [
    "### Load Existing Data File to Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d76ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ld = pd.read_csv (os.path.join(sub_results_+'//'+str(files.start+1)+'_'+str(files.stop)+'_data.csv'), sep = ';')\n",
    "print(os.path.join(sub_results_+'//'+str(files.start+1)+'_'+str(files.stop)+'_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_ld.loc[(df_ld['filename'] == int(f'{125:08}'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e5f897",
   "metadata": {},
   "source": [
    "### RC_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RC_Y = (df_sub.q01_Y - df_sub.q01_Y ) / class_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4190c4",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e262b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
